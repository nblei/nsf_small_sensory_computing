To understand the hardware requirements for emerging earable applications, we
proposed EarBench, a suite of representative emerging earable applications with
diverse sensor-based inputs and computation requirements
(Table~\ref{tab:earbench}). The EarBench applications have been chosen through
a comprehensive survey of earable applications research~\cite{}, personal
correspondence with domain experts~\cite{}, and profiling of earable
applications to ascertain their execution requirements. We analyzed the
performance of EarBench applications on a spectrum of programmable
microprocessors, including those roughly modeled after ARM Cortex M4 and Cortex
M7 (these cores are a part of several current programmable SoCs). We found that
there is a \(3.97\times\) to \(13.54\times\) performance gap between the
computational needs of EarBench applications and the performance of today's
Cortex M4 and Cortex M7 based programmable earable hardware. More complex
microprocessors (e.g., Cortex A53) can meet the performance requirements of
several EarBench applications, but their high power requirements (e.g.,
\SIrange{276}{339}{\milli\watt} for A53) severely restrict functionality (e.g.,
the number of seconds of audio that can be processed, the number of inferences
and localizations that can be performed, etc. before the battery runs out),
rendering them unacceptable.

Our analysis of EarBench applications also shows that such applications are
dominated by a small number of diverse digital signal processing (DSP) and
machine learning (ML) kernels --- GEMM, GEMV, FFT, bilinear filtering, 1d and
2d convolution, and LU decomposition (Fig.~\ref{fig:earable_kernels}). Any
programmable earable hardware must provide high perfor- mance on these kernels.
We proposed SpEaC --- Spatial Earable Computer --- a coarse-grained
reconfigurable spatial architecture (Figure 3) to target earable applications
efficiently. SpEaC has a fixed-point multiplier and adder tree-based
distribute-then- reduce substrate with support for vectorized complex
operations that energy-efficiently accelerates the earable ML and DSP kernels
and that can be configured for each kernel based on its dataflow. A
tightly-coupled scalar, in-order CPU is responsible for configura- tion and
stream-based programming. The CPU also executes code that does not fit well on
the reconfigurable substrate, including non-multiply or add operations in the
earable DSP kernel code. Unlike recent CGRAs such as SoftBrain\cite{} whose
substrate is designed to support general-purpose computation and lacks direct
support for complex operations, SpEaC substrate is optimized for
energy-efficient execution of the earable kernels at the expense of generality.

Across the kernels, SpEaC outperforms programmable cores modeled after M4, M7,
A53, and HiFi4 DSP by \(99.3\times, 32.5\times, 14.8\times\), and \(9.8\times\)
respectively.

At \SI{63}{\milli\watt} in \SI{28}{\nano\meter}, the energy efficiency benefits
are \(1.55\times, 9.04\times, 68.3\times\), and \(32.7\times\) respectively;
energy efficiency benefits are 15.7× - 1087× over a low power Mali T628 MP6
GPU. Kernel-level benefits also translate into application-level benefits.
SpEaC meets application-level performance requirements of 9 out of 11 EarBench
applications; applications can now run for long periods on an ear- able class
battery.


\begin{wrapfigure}{l}{0.5\textwidth}
  \centering
  \input{figs/kernels_breakdown.tex}
  \caption{\small Constituent kernels of EarBench applications.}
  \label{fig:kernels_breakdown}
\end{wrapfigure}



\begin{table}[]
\caption{\small EarBench: Execution characteristics.
\label{tab:earbench_metrics}
`RSS' and `WSS' are resident and working set sizes in \si{\mega\byte}. `Comp.',
`Cond.', `Uncond.', and `Mem.' columns correspond to the percent of dynamic
instructions categorized as computation, conditional branching,
unconditional branching, and memory accessing, respectively. `Inst. Count'
is the dynamic instruction count (in millions). `FPA2M' is the ratio of
floating point arithmetic to bytes of memory accessed (Wav2letter uses
integer arithmetic only).
}
\resizebox{1.0\columnwidth}{!}{%
\begin{tabular}{lllllllll}
\toprule
            & RSS    & WSS   & Inst. Count & Comp.  & Cond.  & Uncond. & Mem.  & FPA2M \\ \midrule
TinySR      & 1.56   & 0.07  & 313         & 36.5   & 4.4    & 2.2     & 56.9  & 0.518 \\
HMT         & 1.77   & $<0.01$ & 14          & 49.2   & 4.4    & 3.4     & 42.7  & 0.878 \\
Ambisonic   & 6.82   & 5.42  & 2,795       & 51.9   & 7.2    & 1.4     & 39.5  & 1.27  \\
SpeakerAuth & 6.40   & 3.62  & 1,520       & 26.6   & 15.4   & 1.5     & 56.4  & 1.07  \\
HRTF        & 8.95   & 3.97  & 2,712       & 59.4   & 12.6   & 1.3     & 26.7  & 1.49  \\
DeepECGCNN  & 1084   & 1071  & 3,295       & 72.5   & 14.4   & 0.01    & 13.1  & 1.00  \\
DeepSpeech  & 226    & 195   & 3,486       & 30.6   & 3.3    & 16.8    & 49.3  & 1.07  \\
TLIO        & 39.8   & 0.5   & 87          & 69.0   & 17.4   & 0.37    & 13.1  & 1.00  \\
Wav2Letter  & 29.7   & 28.1  & 1,077       & 79.4   & 2.01   & 0.06    & 18.4  & (N/A) \\
EKF         & 8.9    & 0.63  & 1,351       & 44.9   & 14.0   & 4.76    & 36.2  & 0.760 \\
ALBERT      & 773    & 767   & 15,213      & 73.7   & 1.77   & 0.18    & 24.3  & 1.00  \\ \bottomrule
\end{tabular}}

\end{table}

Fig.~\ref{fig:earable_results} presents speed-up results for simulations of
SpEaC against cores modeled after Cortex M4 (s\_180), Cortex M7 (ss\_480) and
Cortex A53 (ss\_1000) in the gem5 architectural simulator, as well as against
measured results of a HiFi4 DSP.  Across the computation kernels, SpEaC is 5.1
to \(195\times\) faster than s\_180, 1.2 to \(35\times\) faster than ss\_1000,
and 3.8 to \(12.5\times\) faster than the HiFi4 DSP. SpEaC outperforms ss\_1000
by an average of \(11\times\) and outperforms the HiFi4 DSP by an average of
\(6.57\times\).

\begin{wrapfigure}{L}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{./figs/speedup.pdf}
    \caption{\small
    Speed-up of SpEaC over modeled cores.
    }
    \label{fig:earable_results}
\end{wrapfigure}

\begin{wrapfigure}{L}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{./figs/edp.pdf}
    \caption{\small
    Energy improvement from SpEaC over modeled cores.
    }
    \label{fig:earable_edp}
\end{wrapfigure}

Fig.~\ref{fig:earable_edp} shows the energy benefit of SpEaC relative to the
baseline cores. The benefits are up to \(160\times\) compared against the
microprocessors, and up to over \(42\times\) compared to the DSP.

The percentage of total energy consumption consumed by adders and multiplier
functional units is < 20\% for each kernel. The high overhead of control and
data movement reinforce the importance of minimizing the CGRA network costs
(using a tree, for example), the use of specialized FUs (using only fixed point
adders and multipliers on the substrate, for example), and the associated
memory system. Using kernel speed-up values from simulation, and with the
kernel-breakdown of Fig.~\ref{fig:earable_results}, we estimate the application
level speed-up and energy benefits of SpEaC. Compared against ss\_1000,
significant application level speed-ups are significant: \(3.3\times\) for
Deep- Speech and Ambisonic, \(6.6\times\) to \(9.6\times\) for HRTF audio,
\(3.6\) for the ResNet, \(2.2\times\) for ALBERT, \(6.4\times\) for DeepECGCNN,
and \(8.3\times\) for WaveToLetter. In fact, these speed-ups are achieved
despite ss\_1000 consuming \(2\times\) to \(2.5\times\) more power than SpEaC.
These speed-ups are large enough to allow SpEaC to meet the application-level
requirements of all applications, except ALBERT and EKF. Recall
that s\_180, ss\_480, and ss\_1000 met requirements for 0, 2, and 6 applications
respecitively.

To understand the system-level impact of SpEaC, we also consider non-compute
components. Table 5 lists power and latency of several non-compute components.
The latency overhead of the non-compute components is much smaller than the
estimated latency of Earbench applications on SpEaC. We estimate that, compared
to s\_180, ss\_480 and ss\_1000, the speedup of SpEaC on-average across all
EarBench applications is only reduced by 0.67\%, 0.51\% and 0.33\% respectively,
when the latency of all the non-compute components in Table 5 is added. We
similarly estimated (Figure 6) the number of times different EarBench
applications whose performance requirements are met by the SpEaC can be run on
the SpEaC given the energy budget of a \SI{45.4}{\milli\ampere\hour},
\SI{3.7}{\volt} battery.


\begin{wrapfigure}{L}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{./figs/speakandsensors.png}
    \caption{\small
    Number of runs on SpEaC on a \SI{45.4}{\milli\ampere\hour}, \SI{3.7}{\volt}
    battery.
    }
    \label{fig:earable_system}
\end{wrapfigure}

Our results show that even when the microphone, speaker, BLE and IMU sensor are
simultaneously consuming battery energy, the EarBench applications can still
run hundreds of times. E.g. DeepSpeech on 5s audio can run 849 times before
battery needs recharging; this corresponds to large-vocabulary speech
recognition for 1.14 hours. To validate our estimates, we ported TinySR to
SpEaC, implementing the FFT component on the CGRA. Based on TinySR’s estimates,
we had expected to see a \(2.7\times\) speed-up on SpEaC. Simulation of the SpEaC port
of TinySR showed a \(2.5\times\) speed-up, a -7\% error versus our analytic estimate. A
\(2.5\times\) performance improvement on TinySR also corresponds to a
\(5.8\times\) improvement in energy efficiency, and a \(14.4\times\)
improvement in EDP.


